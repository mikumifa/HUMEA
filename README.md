The original cross-KG datasets (FB15K-DB15K/YAGO15K) comes from MMKB, in which the image embeddings are extracted from the pre-trained VGG16.

    Original dataset: MMKBï¼šhttps://github.com/mniepert/mmkb
    The converted dataset and Image embedding:
    	https://pan.baidu.com/s/1MLGBNyFjb9LLa4urCk4hCA; key:stdt
    PLM model:
    	https://huggingface.co/models
    	Bert: https://huggingface.co/bert-base-uncased
    	Roberta: https://huggingface.co/xlm-roberta-base
    	Albert: https://huggingface.co/albert-base-v2
    	T5: https://huggingface.co/albert-base-v2
    	ChatPLM-6B: https://huggingface.co/THUDM/chatglm2-6b
    	LLaMA-7B: https://huggingface.co/shalomma/llama-7b-embeddings

bash run.sh 42 FB15K-YAGO15K 0.2
